{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Project using NLP (Google Colab Ready)\n",
    "**Project Title:** Natural Language Processing for Sentiment Analysis\n\n",
    "**Objective:** Analyze text data using NLP techniques and build a model to classify sentiment.\n\n",
    "**Tools:** Python, NLTK, TensorFlow, Scikit-learn, Matplotlib, Seaborn\n\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Install and Import Required Libraries\n",
    "!pip install nltk tensorflow seaborn wordcloud\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Import other libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Upload Dataset (CSV Format Expected with a 'text' and 'airline_sentiment' column)\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "import io\n",
    "df = pd.read_csv(io.BytesIO(next(iter(uploaded.values()))))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Data Preprocessing\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\S+|[^a-zA-Z ]', '', text)\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return ' '.join([w for w in tokens if w not in stop_words])\n",
    "\n",
    "df['clean_text'] = df['text'].apply(preprocess)\n",
    "df[['text', 'clean_text']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Visualize Word Cloud\n",
    "text = ' '.join(df['clean_text'])\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Prepare Data for Model\n",
    "X = df['clean_text']\n",
    "y = df['airline_sentiment']\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_vec = vectorizer.fit_transform(X).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_vec, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Train Logistic Regression Model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print("Accuracy:", accuracy_score(y_test, y_pred))\n",
    "print("Classification Report:\n", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… Submission Guide:\n",
    "1. Make sure all cells are run and outputs are visible.\n",
    "2. Save the notebook.\n",
    "3. Click on **Share > Copy link**, ensure it is viewable.\n",
    "4. Submit the link via portal or email."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "NLP_Sentiment_Analysis_Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
